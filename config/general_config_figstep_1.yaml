evaluation:
  evaluator_params:
    default_judge:
      max_tokens: 2000
      max_workers: 4
      model: gpt-4o-mini
      success_threshold: 3
      temperature: 0.0
    model: gpt-4o-mini
  evaluators:
  - default_judge
experiment:
  mode: response_only
  random_seed: 42
  verbose: false
response_generation:
  defenses:
  - None
  model_kwargs:
    max_tokens: 512
    temperature: 0.0
  models:
  - llava-v1.6-mistral-7b-hf
system:
  batch_size: 8
  log_file: logs/experiment_0210.log
  log_level: INFO
  max_workers: 4
  output_dir: output/
test_case_generation:
  attacks:
  - figstep
  input:
    behaviors_file: /mnt/disk1/szchen/VLMBenchmark/repo/OmniSafeBench-MM/dataset/data_full.json
