import signal
import subprocess
import time
import os
import yaml
import requests
import smtplib
from email.mime.text import MIMEText
from email.header import Header

# --- é…ç½®åŒº ---
# Evaluation é˜¶æ®µé€šå¸¸ä¸éœ€è¦ vLLM æœåŠ¡ï¼Œä½†éœ€è¦ç¡®ä¿ä½ çš„ OPENAI_API_KEY å·²è®¾ç½®åœ¨ç¯å¢ƒå˜é‡æˆ– config ä¸­
GENERAL_CONFIG = "config/general_config.yaml"
# æ¨ç†ç»“æœå­˜æ”¾çš„æ ¹ç›®å½•ï¼Œæ ¹æ® README çš„ç›®å½•ç»“æ„æ¨æ–­
RESPONSE_ROOT = "output/responses/None" # å‡è®¾ defense ä¸º None
MODEL_NAMES = [
    "deepseek-vl2"
    # "Qwen3-VL-8B-Instruct", 
    # "Kimi-VL-A3B-Instruct", 
    # "GLM-4.6V-Flash",
    # "Step3-VL-10B", 
    # "Youtu-VL-4B-Instruct",
    # "gemma-3-4b-it",
    # "gemma-3-27b-it",
    # "llava-onevision-qwen2-7b-ov-hf",
    # "InternVL3_5-8B-Flash"
]
ATTACK_METHOD = "figstep" # ä½ è·‘çš„ attack ç±»å‹

# --- é‚®ä»¶é€šçŸ¥é…ç½® ---
def send_email_notification(model_name, status, details=""):
    smtp_server = "smtp.gmail.com"
    smtp_port = 465
    sender_email = "chenshunzhang823@gmail.com"
    password = "noiuuflcwrmyalbf" 
    to_email = "chenshunzhang823@gmail.com"

    subject = f"VLM Eval(Judge): {model_name} - {status}"
    content = f"æ¨¡å‹: {model_name}\nçŠ¶æ€: {status}\nè¯¦æƒ…: {details}\næ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}"

    msg = MIMEText(content, 'plain', 'utf-8')
    msg['Subject'] = Header(subject, 'utf-8')
    msg['From'] = f"H200 Server <{sender_email}>"
    msg['To'] = to_email

    try:
        with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, [to_email], msg.as_string())
        print(f"ğŸ“§ é€šçŸ¥é‚®ä»¶å·²å‘é€ (Status: {status})")
    except Exception as e:
        print(f"âš ï¸ é‚®ä»¶å‘é€å¤±è´¥: {e}")

# --- åŠŸèƒ½å‡½æ•° ---
def setup_eval_config():
    """
    ç»Ÿä¸€é…ç½®è¯„æµ‹æ’ä»¶ä¸º gpt-4o-mini
    """
    with open(GENERAL_CONFIG, 'r') as f:
        config = yaml.safe_load(f)
    
    # è®¾ç½®è¯„æµ‹å™¨
    config['evaluation']['evaluators'] = ["default_judge"]
    # å‡è®¾ä½ åœ¨ model_config.yaml ä¸­å·²ç»å®šä¹‰äº† gpt-4o-mini 
    # æˆ–è€…åœ¨è¿™é‡Œå¼ºåˆ¶æŒ‡å®šå‚æ•°
    if 'evaluator_params' not in config['evaluation']:
        config['evaluation']['evaluator_params'] = {}
    
    # è¿™ä¸€æ­¥å¾ˆå…³é”®ï¼šç¡®ä¿è°ƒç”¨çš„æ˜¯ gpt-4o-mini
    config['evaluation']['evaluator_params']['model'] = "gpt-4o-mini"
    
    with open(GENERAL_CONFIG, 'w') as f:
        yaml.safe_dump(config, f, default_flow_style=False)

# --- ä¸»å¾ªç¯ ---
print(f"ğŸ¬ å¼€å§‹æ‰¹é‡ [Evaluation] ä»»åŠ¡ï¼Œå…± {len(MODEL_NAMES)} ä¸ªæ¨¡å‹...")

# 1. å…ˆå…¨å±€é…ç½® Judge æ¨¡å‹
setup_eval_config()

for i, model in enumerate(MODEL_NAMES):
    # æ ¹æ® README æ‹¼æ¥ response æ–‡ä»¶çš„è·¯å¾„
    # æ ¼å¼é€šå¸¸ä¸º: attack_<attack>_model_<model>.jsonl
    response_file = os.path.join(RESPONSE_ROOT, f"attack_{ATTACK_METHOD}_model_{model}.jsonl")
    
    print(f"\n" + "="*50)
    print(f"âš–ï¸ [{i+1}/{len(MODEL_NAMES)}] è¯„æµ‹æ¨¡å‹å“åº”: {model}")
    
    if not os.path.exists(response_file):
        print(f"âš ï¸ æœªæ‰¾åˆ°å“åº”æ–‡ä»¶ï¼Œè·³è¿‡: {response_file}")
        continue

    try:
        start_eval = time.time()
        print(f"ğŸš€ æ­£åœ¨è¿è¡Œè¯„æµ‹æµæ°´çº¿ (Judge: gpt-4o-mini)...")
        
        # æ ¸å¿ƒå‘½ä»¤ï¼šåˆ‡æ¢åˆ° evaluation é˜¶æ®µï¼Œå¹¶æŒ‡å®š --input-file
        subprocess.run([
            "python", "run_pipeline.py",
            "--config", GENERAL_CONFIG,
            "--stage", "evaluation",
            "--input-file", response_file
        ], check=True)
        
        duration = round((time.time() - start_eval) / 60, 2)
        print(f"âœ… {model} è¯„æµ‹å®Œæˆï¼è€—æ—¶: {duration} mins")
        send_email_notification(model, "Eval Success", f"è¯„æµ‹è€—æ—¶: {duration} mins\nè¾“å…¥æ–‡ä»¶: {response_file}")
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ è¯„æµ‹å¤±è´¥: {e}")
        send_email_notification(model, "Eval Failed", f"Evaluation è¿è¡Œå‡ºé”™:\n{str(e)}")

print("\nğŸ‰ æ‰€æœ‰è¯„æµ‹ä»»åŠ¡å·²å®Œæˆï¼")
send_email_notification("All Models Eval", "Finished", "æ‰€æœ‰æ¨¡å‹çš„ GPT-4o-mini è¯„æµ‹å·²è·‘å®Œã€‚")